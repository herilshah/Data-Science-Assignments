{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3fe7e3-02ff-4d0f-9e8f-ed0cb5a5f957",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5c4b6-e6bd-4af5-9cb8-85926717c576",
   "metadata": {},
   "source": [
    "Lasso Regression is a linear regression model that uses regularization to prevent overfitting and improve the model's generalization performance. Unlike other regression techniques, Lasso Regression uses L1 regularization, which adds a penalty term to the objective function of the regression model, forcing some of the coefficients to become zero. This results in a sparse model where only the most important features are selected, making it useful for feature selection and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b15513-64df-4c35-b010-ae45a884a8d5",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d18916-8b7e-4d1c-bfba-7bca2cb4c965",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is that it automatically selects the most important features in the model and discards the irrelevant ones by setting their corresponding coefficients to zero. This not only simplifies the model but also reduces the risk of overfitting, especially when dealing with a large number of features that may be correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e923d3a-d9a0-4125-9bfc-7153beacb203",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a458e-53f1-40a4-8c89-905fe1bcada3",
   "metadata": {},
   "source": [
    "The coefficients of a Lasso Regression model can be interpreted in two ways: magnitude and sign. The magnitude of a coefficient represents the strength of the relationship between a feature and the target variable, with larger magnitudes indicating stronger relationships. The sign of a coefficient indicates the direction of the relationship, with positive coefficients indicating a positive correlation and negative coefficients indicating a negative correlation. In addition, since Lasso Regression can set some coefficients to zero, the non-zero coefficients are the selected features that are considered to be the most important in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b9a52-16a9-49cc-8382-06a0dbe4ca01",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd663620-8b82-45ff-9b18-8598a25b6d35",
   "metadata": {},
   "source": [
    "The tuning parameter that can be adjusted in Lasso Regression is the regularization parameter, also known as the lambda parameter. This parameter controls the strength of the penalty term added to the objective function of the regression model, which in turn controls the amount of shrinkage applied to the coefficients. A larger lambda value results in more shrinkage and sparser models, while a smaller lambda value results in less shrinkage and more complex models. The choice of lambda value is critical to balancing the trade-off between bias and variance in the model, and it can be determined using cross-validation or other optimization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69aee3e-20d2-4746-8b98-e8140c76c7dc",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad6280-34e8-411b-8582-4768fdb7ffb0",
   "metadata": {},
   "source": [
    "Lasso Regression is primarily designed for linear regression problems, where the target variable is a linear combination of the features. However, Lasso Regression can be used for non-linear regression problems by transforming the features into a higher-dimensional space using basis functions such as polynomials or splines. This allows the model to capture non-linear relationships between the features and the target variable. However, using a large number of basis functions can lead to overfitting, and the choice of basis functions should be carefully selected to avoid this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b95133-c4f4-41b8-8403-aab5f3598bd9",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02bf147-484c-41be-a5e7-2913f16f4777",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression is the type of regularization used. Ridge Regression uses L2 regularization, which adds a penalty term proportional to the square of the magnitude of the coefficients, while Lasso Regression uses L1 regularization, which adds a penalty term proportional to the absolute value of the coefficients. This difference results in a different shrinkage pattern for the coefficients, with Lasso Regression being more likely to set some coefficients to zero and resulting in sparser models. Additionally, Ridge Regression tends to perform better when all the features are relevant to the target variable, while Lasso Regression tends to perform better when only a subset of the features are relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf107f2-7a14-4b9a-96f8-fec79bcf1231",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24ffe2-f271-4d08-9643-d7f116a39089",
   "metadata": {},
   "source": [
    "Lasso Regression can handle multicollinearity in the input features by selecting one of the correlated features and setting the coefficients of the other correlated features to zero. This is because Lasso Regression tends to favor features with larger magnitudes and penalizes the coefficients of less important features, leading to a sparse model. Therefore, when there are two or more correlated features, Lasso Regression may choose one of them and discard the others by setting their corresponding coefficients to zero. This feature selection process can also help to reduce the impact of multicollinearity on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476d471-83cd-4c11-bd1d-b6167cd337da",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21415220-d7b4-47d5-82ac-66de4ef763a3",
   "metadata": {},
   "source": [
    "The optimal value of the regularization parameter (lambda) in Lasso Regression can be chosen using cross-validation or other optimization techniques. The most common method is to perform k-fold cross-validation, where the data is divided into k equal-sized subsets, and the model is trained and tested k times, each time using a different subset as the test set and the rest as the training set. For each value of lambda, the mean squared error (MSE) or another performance metric is computed across all k-folds. The lambda value that gives the lowest MSE or the highest R-squared value is then chosen as the optimal value. Alternatively, other optimization techniques such as grid search or random search can be used to explore a range of lambda values and find the optimal value based on the performance metric. It is important to note that the choice of lambda value is problem-specific, and different values may be optimal for different datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
